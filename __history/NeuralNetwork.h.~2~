class NeuralNetwork;

class Neuron{

private:
  NeuralNetwork *network;

  int mode; //input, output, hidden = 1,2,3
  int function; //sigmoid, por = 1,2

  double *output_weights;
  int layer;
  int position;

  double net;
  double active_signal;
  double displacement;

  double error;
  double learning_rate;

public:

  Neuron(){};
  Neuron(NeuralNetwork *net, int layer, int pos, int mod, int func);

  void calculate_net();
  void active_function();
  void calculate_error(double);
  void update_weights(double);

  double getNet();
  void setNet(double value){net = value;};
  double getActiveSignal(){return active_signal;};
  double getWeight(int);
  int getMode(){return mode;};
  void incrementWeight(int, double);
};

class NeuralNetwork{
	private:

  Neuron **neuro_net_array;
  int n_of_layers;
  int *n_of_neurons_in_layers;

	public:

  NeuralNetwork(int*, int);
  int getNumberOfLayers(){return n_of_layers;};
  int getNumberOfNeuronsInLayer(layer_number){return n_of_neurons_in_layers[layer_number];};
  void LearnEpoch(int *inputdata, int result, TMemo* logMemo);
};

Neuron::Neuron(NeuralNetwork *net, int layer, int pos, int mod, int func){

  net = 0;
  error = 0;
  mode = mod;
  position = pos;
  active_signal = 0;
  displacement = (rand() % 300)/100;
  learning_rate = 0.025;
  function = func;
  network = net;

  if (layer > 0) {
	output_weights = new double[network->getNumberOfNeuronsInLayer(layer-1)];
	for (int i = 0; i < network->getNumberOfNeuronsInLayer(layer-1); i++) {
	  output_weights[i] = (rand() % 300)/100;
	}
  }else{
	output_weights = NULL;
  }

}

void Neuron::calculate_net(){
  //net = 0;
  //for (int i=0; i < n_of_input_neurons; i++) {
	//net = (input_neurons[0]->getActiveSignal());//*(input_neurons[i]->getWeight(position));
  //}
  //net += displacement;
}

void Neuron::active_function(){
  if (function == 2) {
	if(net > 0){
	  active_signal = 1;
	}else{
	  active_signal = 0;
	}
  }else{
	active_signal = 1/(1+exp(-net));  //sigmoid
  }
}

void Neuron::calculate_error(double expected_value){
//
//  if (mode == 2) {
//	  double exp = expected_value;
//	  error = (exp - net)*net*(1-net);
//  }else{
//	double sum = 0;
//	for (int i = 0; i < n_of_output_neurons; i++) {
//	  sum += (output_neurons[i]->error)*(output_weights[i]);
//	}
//	error = sum*net*(1-net);
//  }
}

void Neuron::update_weights(double exit_signal){
//if (mode != 1) {
//  for (int i = 0; i < n_of_output_neurons; i++) {
//	if (mode == 2) {
//	  input_neurons[i]->incrementWeight(position, learning_rate*error*exit_signal);
//	}else{
//	  input_neurons[i]->incrementWeight(position, learning_rate*error*net);
//	}
//	displacement -= learning_rate*error;
//  }
//}
}

double Neuron::getNet(){
  return net;
}

double Neuron::getWeight(int to_element_position){
  return output_weights[to_element_position];
}

void Neuron::incrementWeight(int n_of_output_neuron, double value){
  output_weights[n_of_output_neuron] = value+output_weights[n_of_output_neuron];
}

NeuralNetwork::NeuralNetwork(int* n_of_neurons_in_each_layer, int number_of_layers){
  n_of_layers = number_of_layers;
  n_of_neurons_in_layers = new int[n_of_layers];

  for (int i = 0; i < n_of_layers; i++) {
	n_of_neurons_in_layers[i] = n_of_neurons_in_each_layer[i];
  }

  neuro_net_array = new Neuron*[n_of_layers];
  for (int i = 0 ; i < n_of_layers; i++) {
	neuro_net_array[i] = new Neuron[n_of_neurons_in_layers[i]];
  }
  // int mode; //input, output, hidden = 1,2,3
  //int function; //sigmoid, por = 1,2
  for (int i = 0; i < n_of_layers; i++) {
	for (int j = 0; j<n_of_neurons_in_layers[i]; j++) {
	  int mode;
	  int function;
	  if (i == 0) {
		mode = 1;
		function = 1;
	  }else if ( i == n_of_layers-1){
		mode = 2;
		function = 2;
	  }else{
		mode = 3;
		function = 1;
	  }
	  neuro_net_array[i][j] = *(new Neuron(this, i, j, mode, function));
	}
  }
}

void NeuralNetwork::LearnEpoch(int* inputdata, int result, TMemo* logMemo){
	for(int i = 0; i < n_of_layers; i++){
		for (int j = 0; j < n_of_neurons_in_layers[i]; j++) {
			Neuron neuron = neuro_net_array[i][j];
			logMemo->Lines->Add("Neuron["+AnsiString(i)+"]["+AnsiString(j)+"] Mode:"+AnsiString(neuron.getMode()));
			if(neuron.getMode() == 1){
				neuron.setNet(inputdata[j]);
			}else{
				neuron.calculate_net();
			}
			logMemo->Lines->Add(" network value -> "+AnsiString(neuron.getNet()));
			neuron.active_function();
			logMemo->Lines->Add(" active signal -> "+AnsiString(neuron.getActiveSignal()));

		}
	}
}






